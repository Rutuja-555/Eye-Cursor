The field of Human-Computer Interaction (HCI) has witnessed a tremendous growth in the past decade. The advent tablet PCs and cellphones allowing touch-based control has been hailed warmly. The researchers in this field have also explored the potential of eye-gaze as a possible mean of interaction. Some commercial solutions have already been launched, but they are as yet expensive and offer limited usability. This project strives to develop a low cost real time system for eye-gazed based human- computer interaction.
A high number of people, affected with neuro-locomotor disabilities or those paralyzed by injury cannot use computers for basic tasks such as sending or receiving messages, browsing the internet, watch their favorite TV show or movies. Through a previous research study, it was concluded that eyes are an excellent candidate for ubiquitous computing since they move anyway during interaction with computing machinery. Using this underlying information from eye movements could allow bringing the use of computers back to such patients. For this purpose, we propose an imouse gesture control system which is completely operated by human eyes only. The purpose of this work is to design an open-source generic eye-gesture control system that can effectively track eye-movements and enable the user to perform actions mapped to specific eye movements/gestures by using computer webcam. It detects the pupil from  the userâ€™s face and then tracks its movements. It needs to be accurate in real-time so that the user is able to use it like other every-day devices with comfort.
The idea of eye controls of great use to not only the future of natural input but more importantly the handicapped and disabled. Moreover, implementing a controlling system in it enables them to operate computer without the help of another person.
